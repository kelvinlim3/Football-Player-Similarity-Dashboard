{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1de2d00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preliminaries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import euclidean_distances, manhattan_distances, cosine_similarity\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.stats import skew, kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5572c9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to dataframe csv files\n",
    "DF_FULL_PATH = 'Data/df_full.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fd94b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataframes for each position\n",
    "df_full = pd.read_csv(DF_FULL_PATH, index_col=0)\n",
    "cb_df = df_full[df_full.position=='CB']\n",
    "fb_df = df_full[df_full.position=='FB']\n",
    "dm_df = df_full[df_full.position=='DM']\n",
    "m_df = df_full[df_full.position=='M']\n",
    "w_df = df_full[df_full.position=='W']\n",
    "cf_df = df_full[df_full.position=='CF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "768007ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "RAW_TRAITS = ['goals', 'shots', 'conversion', 'positioning', 'assists', 'crossing', 'dribbling', 'carries',\n",
    "              'involvement', 'accuracy', 'intent', 'receiving', 'aerial', 'on_ball', 'off_ball', 'fouls']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1dcbd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get raw traits per position as numpy array\n",
    "cb_raw_traits = cb_df[RAW_TRAITS].to_numpy()\n",
    "fb_raw_traits = fb_df[RAW_TRAITS].to_numpy()\n",
    "dm_raw_traits = dm_df[RAW_TRAITS].to_numpy()\n",
    "m_raw_traits = m_df[RAW_TRAITS].to_numpy()\n",
    "w_raw_traits = w_df[RAW_TRAITS].to_numpy()\n",
    "cf_raw_traits = cf_df[RAW_TRAITS].to_numpy()\n",
    "\n",
    "raw_traits_dict = {'CB': cb_raw_traits,\n",
    "                   'FB': fb_raw_traits,\n",
    "                   'DM': dm_raw_traits,\n",
    "                   'M': m_raw_traits,\n",
    "                   'W': w_raw_traits,\n",
    "                   'CF': cf_raw_traits\n",
    "                  }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d614014b",
   "metadata": {},
   "source": [
    "### Euclidean Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1bb053c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_similarity(raw_traits):\n",
    "    distances = euclidean_distances(raw_traits)\n",
    "    distances[distances==0] = 0.1\n",
    "    scores = 1 / distances\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c38c8c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "euclidean_scores_cb = euclidean_similarity(cb_raw_traits)\n",
    "euclidean_scores_fb = euclidean_similarity(fb_raw_traits)\n",
    "euclidean_scores_dm = euclidean_similarity(dm_raw_traits)\n",
    "euclidean_scores_m = euclidean_similarity(m_raw_traits)\n",
    "euclidean_scores_w = euclidean_similarity(w_raw_traits)\n",
    "euclidean_scores_cf = euclidean_similarity(cf_raw_traits)\n",
    "\n",
    "euclidean_scores_dict = {'CB': euclidean_scores_cb,\n",
    "                         'FB': euclidean_scores_fb,\n",
    "                         'DM': euclidean_scores_dm,\n",
    "                         'M': euclidean_scores_m,\n",
    "                         'W': euclidean_scores_w,\n",
    "                         'CF': euclidean_scores_cf\n",
    "                        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a101d7ae",
   "metadata": {},
   "source": [
    "### Manhattan Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cec43fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manhattan_similarity(raw_traits):\n",
    "    distances = manhattan_distances(raw_traits)\n",
    "    distances[distances==0] = 0.1\n",
    "    scores = 1 / distances\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eea9fdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "manhattan_scores_cb = manhattan_similarity(cb_raw_traits)\n",
    "manhattan_scores_fb = manhattan_similarity(fb_raw_traits)\n",
    "manhattan_scores_dm = manhattan_similarity(dm_raw_traits)\n",
    "manhattan_scores_m = manhattan_similarity(m_raw_traits)\n",
    "manhattan_scores_w = manhattan_similarity(w_raw_traits)\n",
    "manhattan_scores_cf = manhattan_similarity(cf_raw_traits)\n",
    "\n",
    "manhattan_scores_dict = {'CB': manhattan_scores_cb,\n",
    "                         'FB': manhattan_scores_fb,\n",
    "                         'DM': manhattan_scores_dm,\n",
    "                         'M': manhattan_scores_m,\n",
    "                         'W': manhattan_scores_w,\n",
    "                         'CF': manhattan_scores_cf\n",
    "                        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1288bae4",
   "metadata": {},
   "source": [
    "### Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14d15476",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_scores_cb = cosine_similarity(cb_raw_traits)\n",
    "cosine_scores_fb = cosine_similarity(fb_raw_traits)\n",
    "cosine_scores_dm = cosine_similarity(dm_raw_traits)\n",
    "cosine_scores_m = cosine_similarity(m_raw_traits)\n",
    "cosine_scores_w = cosine_similarity(w_raw_traits)\n",
    "cosine_scores_cf = cosine_similarity(cf_raw_traits)\n",
    "\n",
    "cosine_scores_dict = {'CB': cosine_scores_cb,\n",
    "                      'FB': cosine_scores_fb,\n",
    "                      'DM': cosine_scores_dm,\n",
    "                      'M': cosine_scores_m,\n",
    "                      'W': cosine_scores_w,\n",
    "                      'CF': cosine_scores_cf\n",
    "                     }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6364d6c0",
   "metadata": {},
   "source": [
    "### Adjusted Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0ca9a151",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjusted_cosine_similarity(raw_traits):\n",
    "    reduced_u = raw_traits.mean(axis=1)\n",
    "    reduced_sub = raw_traits - reduced_u[:, None]\n",
    "    scores = 1 - squareform(pdist(reduced_sub, 'cosine'))\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "298a83e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_cosine_scores_cb = adjusted_cosine_similarity(cb_raw_traits)\n",
    "adjusted_cosine_scores_fb = adjusted_cosine_similarity(fb_raw_traits)\n",
    "adjusted_cosine_scores_dm = adjusted_cosine_similarity(dm_raw_traits)\n",
    "adjusted_cosine_scores_m = adjusted_cosine_similarity(m_raw_traits)\n",
    "adjusted_cosine_scores_w = adjusted_cosine_similarity(w_raw_traits)\n",
    "adjusted_cosine_scores_cf = adjusted_cosine_similarity(cf_raw_traits)\n",
    "\n",
    "adjusted_cosine_scores_dict = {'CB': adjusted_cosine_scores_cb,\n",
    "                               'FB': adjusted_cosine_scores_fb,\n",
    "                               'DM': adjusted_cosine_scores_dm,\n",
    "                               'M': adjusted_cosine_scores_m,\n",
    "                               'W': adjusted_cosine_scores_w,\n",
    "                               'CF': adjusted_cosine_scores_cf\n",
    "                              }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a190c5cb",
   "metadata": {},
   "source": [
    "### Pearson Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "63bce896",
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_scores_cb = np.corrcoef(cb_raw_traits)\n",
    "pearson_scores_fb = np.corrcoef(fb_raw_traits)\n",
    "pearson_scores_dm = np.corrcoef(dm_raw_traits)\n",
    "pearson_scores_m = np.corrcoef(m_raw_traits)\n",
    "pearson_scores_w = np.corrcoef(w_raw_traits)\n",
    "pearson_scores_cf = np.corrcoef(cf_raw_traits)\n",
    "\n",
    "pearson_scores_dict = {'CB': pearson_scores_cb,\n",
    "                       'FB': pearson_scores_fb,\n",
    "                       'DM': pearson_scores_dm,\n",
    "                       'M': pearson_scores_m,\n",
    "                       'W': pearson_scores_w,\n",
    "                       'CF': pearson_scores_cf\n",
    "                      }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088eaab7",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11cd42a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_1(scores, raw_traits):\n",
    "    \n",
    "    # get list of predicted ranks of queried players\n",
    "    queried_player_ranks = []\n",
    "    for queried_player_index, scores in enumerate(scores):\n",
    "        player_indices = np.argpartition(scores, -len(raw_traits))\n",
    "        player_indices = np.flip(player_indices[np.argsort(scores[player_indices])])\n",
    "        \n",
    "        for rank, index in enumerate(player_indices):\n",
    "            if index == queried_player_index:\n",
    "                queried_player_ranks.append(rank+1)\n",
    "    \n",
    "    return np.average(queried_player_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c34a2a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_2(scores, raw_traits, top_n=20):\n",
    "\n",
    "    # get list of all averaged ratio stds for each queried player\n",
    "    avg_ratio_stds = []\n",
    "    for queried_player_index, scores in enumerate(scores):\n",
    "\n",
    "        queried_traits = raw_traits[queried_player_index]\n",
    "        queried_traits[np.where(queried_traits==0)] = 0.001 # small epsilon to avoid division by zero\n",
    "        \n",
    "        top_n_indices = np.argpartition(scores, -top_n-1)[-top_n-1:]\n",
    "        top_n_indices = np.flip(top_n_indices[np.argsort(scores[top_n_indices])])\n",
    "        \n",
    "        # get list of ratio std's between queried player and ranked player\n",
    "        ratio_stds = []\n",
    "        for ind in top_n_indices:\n",
    "            # stop loop when top_n players have been processed\n",
    "            if len(ratio_stds) == top_n:\n",
    "                break\n",
    "            # skip queried player\n",
    "            if ind == queried_player_index:\n",
    "                continue\n",
    "                \n",
    "            player_traits = raw_traits[ind]\n",
    "            ratios = player_traits / queried_traits\n",
    "            ratio_std = ratios.std()\n",
    "            ratio_stds.append(ratio_std)\n",
    "\n",
    "        # compute average of ratio stds\n",
    "        avg_ratio_stds.append(np.average(ratio_stds))\n",
    "\n",
    "    return np.average(avg_ratio_stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93cf6991",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_3(scores):\n",
    "    # compute variances of all queries\n",
    "    all_variances = np.var(scores, axis=1)\n",
    "    \n",
    "    return np.average(all_variances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83b60c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_4(scores):\n",
    "    # compute skewness of all queries\n",
    "    all_skews = skew(scores, axis=1)\n",
    "    \n",
    "    return np.average(all_skews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f000024b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_5(scores):\n",
    "    # compute kurtosis of all queries\n",
    "    all_kurtosis = kurtosis(scores, axis=1)\n",
    "    \n",
    "    return np.average(all_kurtosis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3368b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_6(scores):\n",
    "    # get min and max of all scores\n",
    "    min_score = scores.min()\n",
    "    max_score = scores.max()\n",
    "    \n",
    "    return [min_score, max_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0229de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods_dict = {'Euclidean similarity': euclidean_scores_dict,\n",
    "                'Manhattan similarity': manhattan_scores_dict,\n",
    "                'Cosine similarity': cosine_scores_dict,\n",
    "                'Adjusted cosine similarity': adjusted_cosine_scores_dict,\n",
    "                'Pearson correlation': pearson_scores_dict,\n",
    "               }\n",
    "dynamicity_dict = {'Euclidean similarity': 'Y',\n",
    "                   'Manhattan similarity': 'Y',\n",
    "                   'Cosine similarity': 'Y',\n",
    "                   'Adjusted cosine similarity': 'Y',\n",
    "                   'Pearson correlation': 'Y',\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c72742f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {'Method': [],\n",
    "           'Average rank of queried player': [],\n",
    "           'Standard deviation of trait ratios of top 20 similar players': [],\n",
    "           'Scores sparsity': [],\n",
    "           'Skewness of scores': [],\n",
    "           'Kurtosis of scores': [],\n",
    "           'Range of scores': [],\n",
    "           'Dynamicity': []\n",
    "          }\n",
    "\n",
    "for name, dictionary in methods_dict.items():\n",
    "    results['Method'].append(name)\n",
    "    results['Dynamicity'].append(dynamicity_dict[name])\n",
    "    eval_1_list = []\n",
    "    eval_2_list = []\n",
    "    eval_3_list = []\n",
    "    eval_4_list = []\n",
    "    eval_5_list = []\n",
    "    min_score = 99999\n",
    "    max_score = -99999\n",
    "    for pos, scores in dictionary.items():\n",
    "        raw_traits = raw_traits_dict[pos]\n",
    "        eval_1_list.append(eval_1(scores, raw_traits))\n",
    "        eval_2_list.append(eval_2(scores, raw_traits))\n",
    "        eval_3_list.append(eval_3(scores))\n",
    "        eval_4_list.append(eval_4(scores))\n",
    "        eval_5_list.append(eval_5(scores))\n",
    "        temp_min_score, temp_max_score = eval_6(scores)\n",
    "        min_score = min(min_score, temp_min_score)\n",
    "        max_score = max(max_score, temp_max_score)\n",
    "    results['Average rank of queried player'].append(np.average(eval_1_list))\n",
    "    results['Standard deviation of trait ratios of top 20 similar players'].append(np.average(eval_2_list))\n",
    "    results['Scores sparsity'].append(np.average(eval_3_list))\n",
    "    results['Skewness of scores'].append(np.average(eval_4_list))\n",
    "    results['Kurtosis of scores'].append(np.average(eval_5_list))\n",
    "    results['Range of scores'].append([round(min_score, 2), round(max_score, 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61f7c270",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db3e7d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Average rank of queried player</th>\n",
       "      <th>Standard deviation of trait ratios of top 20 similar players</th>\n",
       "      <th>Scores sparsity</th>\n",
       "      <th>Skewness of scores</th>\n",
       "      <th>Kurtosis of scores</th>\n",
       "      <th>Range of scores</th>\n",
       "      <th>Dynamicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Euclidean similarity</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.371310</td>\n",
       "      <td>0.100881</td>\n",
       "      <td>29.132255</td>\n",
       "      <td>920.561954</td>\n",
       "      <td>[0.06, 10.0]</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Manhattan similarity</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.399121</td>\n",
       "      <td>0.097810</td>\n",
       "      <td>32.195386</td>\n",
       "      <td>1057.538564</td>\n",
       "      <td>[0.02, 10.0]</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cosine similarity</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.360389</td>\n",
       "      <td>0.001345</td>\n",
       "      <td>-1.354056</td>\n",
       "      <td>5.572576</td>\n",
       "      <td>[0.28, 1.0]</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adjusted cosine similarity</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.376132</td>\n",
       "      <td>0.132210</td>\n",
       "      <td>0.093123</td>\n",
       "      <td>-0.704145</td>\n",
       "      <td>[-0.96, 1.0]</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pearson correlation</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.376132</td>\n",
       "      <td>0.132210</td>\n",
       "      <td>0.093123</td>\n",
       "      <td>-0.704145</td>\n",
       "      <td>[-0.96, 1.0]</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Method  Average rank of queried player  \\\n",
       "0        Euclidean similarity                             1.0   \n",
       "1        Manhattan similarity                             1.0   \n",
       "2           Cosine similarity                             1.0   \n",
       "3  Adjusted cosine similarity                             1.0   \n",
       "4         Pearson correlation                             1.0   \n",
       "\n",
       "   Standard deviation of trait ratios of top 20 similar players  \\\n",
       "0                                           0.371310              \n",
       "1                                           0.399121              \n",
       "2                                           0.360389              \n",
       "3                                           0.376132              \n",
       "4                                           0.376132              \n",
       "\n",
       "   Scores sparsity  Skewness of scores  Kurtosis of scores Range of scores  \\\n",
       "0         0.100881           29.132255          920.561954    [0.06, 10.0]   \n",
       "1         0.097810           32.195386         1057.538564    [0.02, 10.0]   \n",
       "2         0.001345           -1.354056            5.572576     [0.28, 1.0]   \n",
       "3         0.132210            0.093123           -0.704145    [-0.96, 1.0]   \n",
       "4         0.132210            0.093123           -0.704145    [-0.96, 1.0]   \n",
       "\n",
       "  Dynamicity  \n",
       "0          Y  \n",
       "1          Y  \n",
       "2          Y  \n",
       "3          Y  \n",
       "4          Y  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
